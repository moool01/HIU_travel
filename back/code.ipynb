{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "281f4690",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# ì—‘ì…€ íŒŒì¼ ë¶ˆëŸ¬ì˜¤ê¸°\n",
    "df = pd.read_csv(\"../ì „ì²˜ë¦¬/data_d.csv\")  # ë˜ëŠ” pd.read_csv(\"íŒŒì¼ëª….csv\")\n",
    "\n",
    "# ëª¨ë“  ì—´ì´ NaNì¸ í–‰ ì œê±°\n",
    "df_cleaned = df.dropna(how='all')\n",
    "\n",
    "# ì¸ë±ìŠ¤ ì´ˆê¸°í™” (ê¸°ì¡´ ì¸ë±ìŠ¤ ë¬´ì‹œí•˜ê³  0ë¶€í„° ì¬ì •ë ¬)\n",
    "df_cleaned.reset_index(drop=True, inplace=True)\n",
    "\n",
    "# ì €ì¥ (ì„ íƒ)\n",
    "df_cleaned.to_csv(\"../ì „ì²˜ë¦¬/data_d.csv\", index=False)  # ë˜ëŠ” to_csv(...)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5a7d3dd0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'encoding': 'EUC-KR', 'confidence': 0.99, 'language': 'Korean'}\n"
     ]
    }
   ],
   "source": [
    "import chardet\n",
    "\n",
    "with open(\"food_ìŒì‹ì ë°ì´í„°.csv\", \"rb\") as f:\n",
    "    result = chardet.detect(f.read())\n",
    "    print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "485e9506",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['ID', 'ëª…ì¹­', 'ìš°í¸ë²ˆí˜¸', 'ê´€ë¦¬ì', 'ë¬¸ì˜ ë° ì•ˆë‚´', 'ì£¼ì†Œ', 'ìœ„ë„', 'ê²½ë„', 'ê°œìš”', 'ì£¼ì°¨ ì‹œì„¤', 'ì–´ë¦°ì´ë†€ì´ë°©', 'ì˜ì—…ì‹œê°„', 'ì‰¬ëŠ”ë‚ ', 'ëŒ€í‘œë©”ë‰´', 'ì·¨ê¸‰ë©”ë‰´', 'ê¸ˆì—°/í¡ì—°', 'ì‹ ìš©ì¹´ë“œì •ë³´', 'í¬ì¥ê°€ëŠ¥', 'ì˜ˆì•½ì•ˆë‚´', 'ìƒì„¸ì •ë³´', 'ì¹´í˜/ìŒì‹ì ']\n"
     ]
    }
   ],
   "source": [
    "restaurants = pd.read_csv(\"food_ìŒì‹ì ë°ì´í„°.csv\",encoding='EUC-KR')\n",
    "print(restaurants.columns.tolist())\n",
    "restaurants.dropna(subset=['ìœ„ë„', 'ê²½ë„'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "970f471f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸš© ì¶œë°œì§€ ê¸°ì¤€ ê´€ê´‘ì§€ ì¶”ì²œ ì¤‘...\n",
      "                     id       name category        theme  \\\n",
      "0   KCLANPO23N000000368    ì œì£¼ê´€ê´‘ì•ˆë‚´ì†Œ      ê´€ê´‘ì§€    ê´€ê´‘ì•ˆë‚´ì†Œ/ë§¤í‘œì†Œ   \n",
      "1   KCLANPO23N000000562     ë„ë‘í•­ìœ ëŒì„       ê´€ê´‘ì§€        ì¼ë°˜ê´€ê´‘ì§€   \n",
      "2   KCLANPO23N000000563        í•´ì‹ ì‚¬      ê´€ê´‘ì§€        ì²œì—°ê¸°ë…ë¬¼   \n",
      "3   KCLANPO23N000000654     ì œì£¼ê³µë£¡ëœë“œ      ê´€ê´‘ì§€  í…Œë§ˆê³µì›/ëŒ€í˜•ë†€ì´ê³µì›   \n",
      "4   KCLANPO23N000000710     ì‚¼ì–‘í•´ìˆ˜ìš•ì¥      ê´€ê´‘ì§€         í•´ìˆ˜ìš•ì¥   \n",
      "..                  ...        ...      ...          ...   \n",
      "88  KCLANPO23N000043167    ë…¸í˜•ìˆ˜í¼ë§ˆì¼“2      ê´€ê´‘ì§€        ì¼ë°˜ê´€ê´‘ì§€   \n",
      "89  KCLANPO23N000043260  ì œì£¼ì „ë†ë¡œë²šê½ƒê±°ë¦¬      ê´€ê´‘ì§€        ìœ ëª…ê´€ê´‘ì§€   \n",
      "90  KCLANPO23N000044514      ìºë‹ˆì–¸íŒŒí¬      ê´€ê´‘ì§€          ë™ë¬¼ì›   \n",
      "91  KCLANPO23N000045412    ìˆ²ì†ì•¼ì˜ì¥íœ´ë¦¼      ê´€ê´‘ì§€          ì•¼ì˜ì¥   \n",
      "92  KCLANPO23N000046372    ì´í˜¸í…Œìš°ë§ë“±ëŒ€      ê´€ê´‘ì§€        ì¼ë°˜ê´€ê´‘ì§€   \n",
      "\n",
      "                     address address_detail        lat         lng  tags/0  \\\n",
      "0      ì œì£¼íŠ¹ë³„ìì¹˜ë„ ì œì£¼ì‹œ ìš©ë‹´ì´ë™  483        ìš©ë‘ì•”ê¸¸ 15  33.514842  126.511421     ë§¤í‘œì†Œ   \n",
      "1   ì œì£¼íŠ¹ë³„ìì¹˜ë„ ì œì£¼ì‹œ ë„ë‘ì¼ë™  268455       ë„ë‘í•­ì„œê¸¸ 28  33.506616  126.465123   ì¼ë°˜ê´€ê´‘ì§€   \n",
      "2     ì œì£¼íŠ¹ë³„ìì¹˜ë„ ì œì£¼ì‹œ í™”ë¶ì¼ë™  1622      ì§„ë¶ê¸¸ 9ì›” 1ì¼  33.524233  126.565388   ì²œì—°ê¸°ë…ë¬¼   \n",
      "3   ì œì£¼íŠ¹ë³„ìì¹˜ë„ ì œì£¼ì‹œ ì• ì›”ì ê´‘ë ¹ë¦¬ 2698       ê´‘ë ¹í‰í™”2ê¸¸ 1  33.441749  126.433186  ëŒ€í˜•ë†€ì´ê³µì›   \n",
      "4    ì œì£¼íŠ¹ë³„ìì¹˜ë„ ì œì£¼ì‹œ ì‚¼ì–‘ì´ë™  22037           ì •ë³´ì—†ìŒ  33.525612  126.585753    í•´ìˆ˜ìš•ì¥   \n",
      "..                       ...            ...        ...         ...     ...   \n",
      "88    ì œì£¼íŠ¹ë³„ìì¹˜ë„ ì œì£¼ì‹œ í•´ì•ˆë™  86565         ë…¸í˜•ë¡œ 89  33.464962  126.455131       N   \n",
      "89    ì œì£¼íŠ¹ë³„ìì¹˜ë„ ì œì£¼ì‹œ ì‚¼ë„ì¼ë™  1230           ì •ë³´ì—†ìŒ  33.504420  126.518158      ì œì£¼   \n",
      "90    ì œì£¼íŠ¹ë³„ìì¹˜ë„ ì œì£¼ì‹œ ì—°ë™  281-20         ì‚¼ë¬´ë¡œ 51  33.490236  126.492224      ì œì£¼   \n",
      "91  ì œì£¼íŠ¹ë³„ìì¹˜ë„ ì œì£¼ì‹œ ì• ì›”ì ê´‘ë ¹ë¦¬ 2873       ê´‘ë ¹ë‚¨ì„œê¸¸ 40  33.443778  126.428783    ì„œë¶€ì§€ì—­   \n",
      "92  ì œì£¼íŠ¹ë³„ìì¹˜ë„ ì œì£¼ì‹œ ì´í˜¸ì¼ë™  375-43           ì •ë³´ì—†ìŒ  33.501849  126.452081   ì¼ë°˜ê´€ê´‘ì§€   \n",
      "\n",
      "   tags/1 tags/2 tags/3 description main_menu opening_hours closed phone  \\\n",
      "0      ì œì£¼  ê´€ê´‘ì•ˆë‚´ì†Œ    NaN        ì •ë³´ì—†ìŒ      ì •ë³´ì—†ìŒ          ì •ë³´ì—†ìŒ   ì •ë³´ì—†ìŒ  ì •ë³´ì—†ìŒ   \n",
      "1      ì œì£¼    NaN    NaN        ì •ë³´ì—†ìŒ      ì •ë³´ì—†ìŒ          ì •ë³´ì—†ìŒ   ì •ë³´ì—†ìŒ  ì •ë³´ì—†ìŒ   \n",
      "2      ì œì£¼    NaN    NaN        ì •ë³´ì—†ìŒ      ì •ë³´ì—†ìŒ          ì •ë³´ì—†ìŒ   ì •ë³´ì—†ìŒ  ì •ë³´ì—†ìŒ   \n",
      "3      ì œì£¼   ì„œë¶€ì§€ì—­   í…Œë§ˆê³µì›        ì •ë³´ì—†ìŒ      ì •ë³´ì—†ìŒ          ì •ë³´ì—†ìŒ   ì •ë³´ì—†ìŒ  ì •ë³´ì—†ìŒ   \n",
      "4      ì œì£¼    NaN    NaN        ì •ë³´ì—†ìŒ      ì •ë³´ì—†ìŒ          ì •ë³´ì—†ìŒ   ì •ë³´ì—†ìŒ  ì •ë³´ì—†ìŒ   \n",
      "..    ...    ...    ...         ...       ...           ...    ...   ...   \n",
      "88     ì œì£¼    NaN    NaN        ì •ë³´ì—†ìŒ      ì •ë³´ì—†ìŒ          ì •ë³´ì—†ìŒ   ì •ë³´ì—†ìŒ  ì •ë³´ì—†ìŒ   \n",
      "89  ìœ ëª…ê´€ê´‘ì§€    NaN    NaN        ì •ë³´ì—†ìŒ      ì •ë³´ì—†ìŒ          ì •ë³´ì—†ìŒ   ì •ë³´ì—†ìŒ  ì •ë³´ì—†ìŒ   \n",
      "90    ë™ë¬¼ì›    NaN    NaN        ì •ë³´ì—†ìŒ      ì •ë³´ì—†ìŒ          ì •ë³´ì—†ìŒ   ì •ë³´ì—†ìŒ  ì •ë³´ì—†ìŒ   \n",
      "91     ì œì£¼    ì•¼ì˜ì¥    NaN        ì •ë³´ì—†ìŒ      ì •ë³´ì—†ìŒ          ì •ë³´ì—†ìŒ   ì •ë³´ì—†ìŒ  ì •ë³´ì—†ìŒ   \n",
      "92     ì œì£¼    NaN    NaN        ì •ë³´ì—†ìŒ      ì •ë³´ì—†ìŒ          ì •ë³´ì—†ìŒ   ì •ë³´ì—†ìŒ  ì •ë³´ì—†ìŒ   \n",
      "\n",
      "   theme_category tags/4  distance_km  \n",
      "0       ê´€ê´‘ì•ˆë‚´ì†Œ/ë§¤í‘œì†Œ    NaN         1.78  \n",
      "1            ê´€ê´‘ëª…ì†Œ    NaN         2.62  \n",
      "2            ìì—°ê²½ê´€    NaN         6.90  \n",
      "3           ì²´í—˜/ë ˆì €    NaN         9.48  \n",
      "4              ë°”ë‹¤    NaN         8.79  \n",
      "..            ...    ...          ...  \n",
      "88           ê´€ê´‘ëª…ì†Œ    NaN         6.20  \n",
      "89           ê´€ê´‘ëª…ì†Œ    NaN         2.47  \n",
      "90          ì²´í—˜/ë ˆì €    NaN         2.32  \n",
      "91          ì²´í—˜/ë ˆì €    NaN         9.55  \n",
      "92           ê´€ê´‘ëª…ì†Œ    NaN         3.92  \n",
      "\n",
      "[93 rows x 20 columns]\n",
      "\n",
      "ğŸ½ ê´€ê´‘ì§€ ê¸°ì¤€ ìŒì‹ì  ì¶”ì²œ ì¤‘...\n",
      "âœ… ì¶”ì²œ ìŒì‹ì : í•´ì§„íšŸì§‘ (1.63 km)\n",
      "\n",
      "â˜• ìŒì‹ì  ê¸°ì¤€ ì¹´í˜ ì¶”ì²œ ì¤‘...\n",
      "âœ… ì¶”ì²œ ì¹´í˜: ë§ˆìŒì—ì˜¨ (0.48 km)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from geopy.distance import geodesic\n",
    "\n",
    "# ------------------------\n",
    "# 1. ë°ì´í„° ë¶ˆëŸ¬ì˜¤ê¸°\n",
    "# ------------------------\n",
    "attractions = pd.read_csv(\"data_d.csv\")  # ê´€ê´‘ì§€\n",
    "# restaurants = pd.read_csv(\"food_ìŒì‹ì ë°ì´í„°.csv\")\n",
    "cafes = pd.read_csv(\"food_ì¹´í˜ë°ì´í„°.csv\")              # ì¹´í˜\n",
    "# í•œê¸€ ì»¬ëŸ¼ëª…ì„ ì˜ë¬¸ìœ¼ë¡œ ë³€ê²½\n",
    "attractions.rename(columns={'ìœ„ë„': 'lat', 'ê²½ë„': 'lng','ëª…ì¹­':'name'}, inplace=True)\n",
    "restaurants.rename(columns={'ìœ„ë„': 'lat', 'ê²½ë„': 'lng','ëª…ì¹­':'name'}, inplace=True)\n",
    "cafes.rename(columns={'ìœ„ë„': 'lat', 'ê²½ë„': 'lng','ëª…ì¹­':'name'}, inplace=True)\n",
    "# ------------------------\n",
    "# 2. ê±°ë¦¬ ê¸°ë°˜ í•„í„° í•¨ìˆ˜\n",
    "# ------------------------\n",
    "def filter_by_distance(df, center_lat, center_lng, radius_km):\n",
    "    filtered = []\n",
    "    for _, row in df.iterrows():\n",
    "        dist = geodesic((center_lat, center_lng), (row['lat'], row['lng'])).km\n",
    "        if dist <= radius_km:\n",
    "            row_dict = row.to_dict()\n",
    "            row_dict['distance_km'] = round(dist, 2)\n",
    "            filtered.append(row_dict)\n",
    "    return pd.DataFrame(filtered)\n",
    "\n",
    "# ------------------------\n",
    "# 3. ì¶”ì²œ ë¡œì§\n",
    "# ------------------------\n",
    "def recommend_chain(start_lat, start_lng):\n",
    "    print(\"ğŸš© ì¶œë°œì§€ ê¸°ì¤€ ê´€ê´‘ì§€ ì¶”ì²œ ì¤‘...\")\n",
    "    nearby_attractions = filter_by_distance(attractions, start_lat, start_lng, radius_km=10)\n",
    "    \n",
    "    if nearby_attractions.empty:\n",
    "        print(\"âŒ 100km ì´ë‚´ ê´€ê´‘ì§€ê°€ ì—†ìŠµë‹ˆë‹¤.\")\n",
    "        return\n",
    "    \n",
    "    top_attraction = nearby_attractions.iloc[0]\n",
    "    print(nearby_attractions)\n",
    "    # print(f\"âœ… ì¶”ì²œ ê´€ê´‘ì§€: {top_attraction['name']} ({top_attraction['distance_km']} km)\")\n",
    "    \n",
    "    print(\"\\nğŸ½ ê´€ê´‘ì§€ ê¸°ì¤€ ìŒì‹ì  ì¶”ì²œ ì¤‘...\")\n",
    "    nearby_restaurants = filter_by_distance(restaurants, top_attraction['lat'], top_attraction['lng'], radius_km=10)\n",
    "    \n",
    "    if nearby_restaurants.empty:\n",
    "        print(\"âŒ 20ë¶„ ì´ë‚´ ìŒì‹ì ì´ ì—†ìŠµë‹ˆë‹¤.\")\n",
    "        return\n",
    "    \n",
    "    top_restaurant = nearby_restaurants.iloc[0]\n",
    "    print(f\"âœ… ì¶”ì²œ ìŒì‹ì : {top_restaurant['name']} ({top_restaurant['distance_km']} km)\")\n",
    "\n",
    "    print(\"\\nâ˜• ìŒì‹ì  ê¸°ì¤€ ì¹´í˜ ì¶”ì²œ ì¤‘...\")\n",
    "    nearby_cafes = filter_by_distance(cafes, top_restaurant['lat'], top_restaurant['lng'], radius_km=5)\n",
    "    \n",
    "    if nearby_cafes.empty:\n",
    "        print(\"âŒ 10ë¶„ ì´ë‚´ ì¹´í˜ê°€ ì—†ìŠµë‹ˆë‹¤.\")\n",
    "        return\n",
    "    \n",
    "    top_cafe = nearby_cafes.iloc[0]\n",
    "    print(f\"âœ… ì¶”ì²œ ì¹´í˜: {top_cafe['name']} ({top_cafe['distance_km']} km)\")\n",
    "\n",
    "# ------------------------\n",
    "# ì‚¬ìš© ì˜ˆì‹œ\n",
    "# ------------------------\n",
    "# ì˜ˆ: ì„œìš¸ ì‹œì²­ ì¶œë°œ\n",
    "recommend_chain(start_lat=33.511111, start_lng=\t126.492778)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4477d53",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ìµœì˜ì¥êµ°ì‚¬ë‹¹: 404.32 km\n",
      "ìƒì¶”ìì „ë§ëŒ€: 404.53 km\n",
      "ì œì£¼ì˜¬ë ˆ23: 404.62 km\n",
      "í›„í¬í•´ë³€: 404.69 km\n",
      "ì˜ˆì´ˆë¦¬ê¸°ì •ê¸¸ë: 404.79 km\n"
     ]
    }
   ],
   "source": [
    "# ê±°ë¦¬ ê³„ì‚° í›„ ì „ë¶€ ì •ë ¬í•´ì„œ ìƒìœ„ 5ê°œ í™•ì¸\n",
    "def print_nearest(df, center_lat, center_lng):\n",
    "    distances = []\n",
    "    for _, row in df.iterrows():\n",
    "        if pd.isna(row['lat']) or pd.isna(row['lng']):\n",
    "            continue\n",
    "        try:\n",
    "            dist = geodesic((center_lat, center_lng), (row['lat'], row['lng'])).km\n",
    "            distances.append((row['name'], dist))\n",
    "        except:\n",
    "            continue\n",
    "\n",
    "    sorted_result = sorted(distances, key=lambda x: x[1])\n",
    "    for name, d in sorted_result[:5]:\n",
    "        print(f\"{name}: {round(d, 2)} km\")\n",
    "\n",
    "# í™•ì¸ ì‹¤í–‰\n",
    "print_nearest(attractions, 37.511111, 126.9780)  # ì„œìš¸ ì‹œì²­"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e5801ac4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ” ë°˜ê²½ 50km ë‚´ ê²€ìƒ‰ ì¤‘...\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'filter_by_distance' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[12], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m radius \u001b[38;5;129;01min\u001b[39;00m [\u001b[38;5;241m50\u001b[39m, \u001b[38;5;241m100\u001b[39m, \u001b[38;5;241m500\u001b[39m, \u001b[38;5;241m1000\u001b[39m, \u001b[38;5;241m2000\u001b[39m]:\n\u001b[1;32m      2\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mğŸ” ë°˜ê²½ \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mradius\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124mkm ë‚´ ê²€ìƒ‰ ì¤‘...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m----> 3\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43mfilter_by_distance\u001b[49m(attractions, \u001b[38;5;241m37.5665\u001b[39m, \u001b[38;5;241m126.9780\u001b[39m, radius_km\u001b[38;5;241m=\u001b[39mradius)\n\u001b[1;32m      4\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m result\u001b[38;5;241m.\u001b[39mempty:\n\u001b[1;32m      5\u001b[0m         \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mâœ… \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mradius\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124mkm ì´ë‚´ì— \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(result)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124mê°œì˜ ê´€ê´‘ì§€ê°€ ìˆìŠµë‹ˆë‹¤.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'filter_by_distance' is not defined"
     ]
    }
   ],
   "source": [
    "for radius in [50, 100, 500, 1000, 2000]:\n",
    "    print(f\"ğŸ” ë°˜ê²½ {radius}km ë‚´ ê²€ìƒ‰ ì¤‘...\")\n",
    "    result = filter_by_distance(attractions, 37.5665, 126.9780, radius_km=radius)\n",
    "    if not result.empty:\n",
    "        print(f\"âœ… {radius}km ì´ë‚´ì— {len(result)}ê°œì˜ ê´€ê´‘ì§€ê°€ ìˆìŠµë‹ˆë‹¤.\")\n",
    "        break\n",
    "else:\n",
    "    print(\"âŒ ì–´ëŠ ë°˜ê²½ì—ì„œë„ ê´€ê´‘ì§€ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b851aa97",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ìŒì‹ì  NaN ìˆ˜:\n",
      " lat    0\n",
      "lng    0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(\"ìŒì‹ì  NaN ìˆ˜:\\n\", restaurants[['lat', 'lng']].isna().sum())\n",
    "# print(\"ì¹´í˜ NaN ìˆ˜:\\n\", cafes[['ìœ„ë„', 'ê²½ë„']].isna().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "045d0107",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸš© ì¶œë°œì§€ ê¸°ì¤€ ê´€ê´‘ì§€ ì¶”ì²œ ì¤‘...\n",
      "âœ… ì¶”ì²œ ê´€ê´‘ì§€: ì œì£¼ì¹´í˜ê±°ë¦¬ (0.9 km)\n",
      "\n",
      "ğŸ½ ê´€ê´‘ì§€ ê¸°ì¤€ ìŒì‹ì  ì¶”ì²œ ì¤‘...\n",
      "âœ… ì¶”ì²œ ìŒì‹ì : í•´ë…€ì ìˆ˜ì´Œ (0.09 km)\n",
      "\n",
      "â˜• ìŒì‹ì  ê¸°ì¤€ ì¹´í˜ ì¶”ì²œ ì¤‘...\n",
      "âœ… ì¶”ì²œ ì¹´í˜: í™‰íˆ (0.28 km)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from geopy.distance import geodesic\n",
    "\n",
    "# ------------------------\n",
    "# 1. ë°ì´í„° ë¶ˆëŸ¬ì˜¤ê¸°\n",
    "# ------------------------\n",
    "attractions = pd.read_csv(\"data_d.csv\")\n",
    "restaurants = pd.read_csv(\"food_ìŒì‹ì ë°ì´í„°.csv\",encoding='EUC-KR')\n",
    "cafes = pd.read_csv(\"food_ì¹´í˜ë°ì´í„°.csv\", encoding='utf-8-sig')\n",
    "\n",
    "# í•œê¸€ ì»¬ëŸ¼ëª…ì„ ì˜ë¬¸ìœ¼ë¡œ ë³€ê²½\n",
    "attractions.rename(columns={'ìœ„ë„': 'lat', 'ê²½ë„': 'lng', 'ëª…ì¹­': 'name'}, inplace=True)\n",
    "restaurants.rename(columns={'ìœ„ë„': 'lat', 'ê²½ë„': 'lng', 'ëª…ì¹­': 'name'}, inplace=True)\n",
    "cafes.rename(columns={'ìœ„ë„': 'lat', 'ê²½ë„': 'lng', 'ëª…ì¹­': 'name'}, inplace=True)\n",
    "\n",
    "# NaN ì œê±°\n",
    "attractions.dropna(subset=['lat', 'lng'], inplace=True)\n",
    "restaurants.dropna(subset=['lat', 'lng'], inplace=True)\n",
    "cafes.dropna(subset=['lat', 'lng'], inplace=True)\n",
    "\n",
    "# ------------------------\n",
    "# 2. ë¸Œë£¨íŠ¸í¬ìŠ¤ ê±°ë¦¬ ê³„ì‚° í•¨ìˆ˜\n",
    "# ------------------------\n",
    "def find_closest_place(df, center_lat, center_lng):\n",
    "    closest = None\n",
    "    min_distance = float('inf')\n",
    "\n",
    "    for _, row in df.iterrows():\n",
    "        try:\n",
    "            dist = geodesic((center_lat, center_lng), (row['lat'], row['lng'])).km\n",
    "            if dist < min_distance:\n",
    "                min_distance = dist\n",
    "                closest = row.to_dict()\n",
    "                closest['distance_km'] = round(dist, 2)\n",
    "        except:\n",
    "            continue\n",
    "\n",
    "    return closest\n",
    "\n",
    "# ------------------------\n",
    "# 3. ì¶”ì²œ ì²´ì¸ ë¡œì§\n",
    "# ------------------------\n",
    "def recommend_chain(start_lat, start_lng):\n",
    "    print(\"ğŸš© ì¶œë°œì§€ ê¸°ì¤€ ê´€ê´‘ì§€ ì¶”ì²œ ì¤‘...\")\n",
    "    top_attraction = find_closest_place(attractions, start_lat, start_lng)\n",
    "\n",
    "    if not top_attraction:\n",
    "        print(\"âŒ ê´€ê´‘ì§€ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.\")\n",
    "        return\n",
    "\n",
    "    print(f\"âœ… ì¶”ì²œ ê´€ê´‘ì§€: {top_attraction['name']} ({top_attraction['distance_km']} km)\")\n",
    "\n",
    "    print(\"\\nğŸ½ ê´€ê´‘ì§€ ê¸°ì¤€ ìŒì‹ì  ì¶”ì²œ ì¤‘...\")\n",
    "    top_restaurant = find_closest_place(restaurants, top_attraction['lat'], top_attraction['lng'])\n",
    "\n",
    "    if not top_restaurant:\n",
    "        print(\"âŒ ê°€ê¹Œìš´ ìŒì‹ì ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.\")\n",
    "        return\n",
    "\n",
    "    print(f\"âœ… ì¶”ì²œ ìŒì‹ì : {top_restaurant['name']} ({top_restaurant['distance_km']} km)\")\n",
    "\n",
    "    print(\"\\nâ˜• ìŒì‹ì  ê¸°ì¤€ ì¹´í˜ ì¶”ì²œ ì¤‘...\")\n",
    "    top_cafe = find_closest_place(cafes, top_restaurant['lat'], top_restaurant['lng'])\n",
    "\n",
    "    if not top_cafe:\n",
    "        print(\"âŒ ê°€ê¹Œìš´ ì¹´í˜ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.\")\n",
    "        return\n",
    "\n",
    "    print(f\"âœ… ì¶”ì²œ ì¹´í˜: {top_cafe['name']} ({top_cafe['distance_km']} km)\")\n",
    "\n",
    "# ------------------------\n",
    "# ì‚¬ìš© ì˜ˆì‹œ\n",
    "# ------------------------\n",
    "recommend_chain(start_lat=33.511111, start_lng=\t126.492778)\n",
    "# print_nearest(attractions, 37.511111, 126.9780)  # ì„œìš¸ ì‹œì²­"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "48694cde",
   "metadata": {},
   "outputs": [],
   "source": [
    "from geopy.distance import geodesic\n",
    "\n",
    "def score_places(df, user_lat, user_lng, user_category, max_distance_km=10, w_content=0.7, w_distance=0.3):\n",
    "    scored = []\n",
    "\n",
    "    for _, row in df.iterrows():\n",
    "        try:\n",
    "            lat, lng = row['lat'], row['lng']\n",
    "            if pd.isna(lat) or pd.isna(lng):\n",
    "                continue\n",
    "\n",
    "            distance = geodesic((user_lat, user_lng), (lat, lng)).km\n",
    "            if distance > max_distance_km:\n",
    "                continue  # ë„ˆë¬´ ë¨¼ ì¥ì†ŒëŠ” ì œì™¸\n",
    "\n",
    "            # ì½˜í…ì¸  ì ìˆ˜ (ì¹´í…Œê³ ë¦¬ ì¼ì¹˜ ì—¬ë¶€)\n",
    "            content_score = 1 if row.get('theme_category', '') == user_category else 0\n",
    "\n",
    "            # ê±°ë¦¬ ì ìˆ˜ ê³„ì‚° (1 - ê±°ë¦¬/ìµœëŒ€ê±°ë¦¬)\n",
    "            distance_score = 1 - (distance / max_distance_km)\n",
    "\n",
    "            # ìµœì¢… ì ìˆ˜\n",
    "            final_score = w_content * content_score + w_distance * distance_score\n",
    "\n",
    "            row_data = row.to_dict()\n",
    "            row_data['distance_km'] = round(distance, 2)\n",
    "            row_data['content_score'] = content_score\n",
    "            row_data['distance_score'] = round(distance_score, 2)\n",
    "            row_data['final_score'] = round(final_score, 4)\n",
    "            scored.append(row_data)\n",
    "\n",
    "        except:\n",
    "            continue\n",
    "\n",
    "    return pd.DataFrame(scored).sort_values('final_score', ascending=False).head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "745bfd4c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       name theme_category  distance_km  content_score  distance_score  \\\n",
      "75   ì œì£¼ì¹´í˜ê±°ë¦¬             ê¸°íƒ€         0.90              0            0.91   \n",
      "21  ìš©ë‘ì•”í•´ì•ˆë„ë¡œ           ê´€ê´‘ëª…ì†Œ         1.06              0            0.89   \n",
      "36     ì„ ì‚¬ë¬´ë¤        ì—­ì‚¬/ë¬¸í™”ìœ ì‚°         1.28              0            0.87   \n",
      "12    ì„ ì‚¬ì£¼ê±°ì§€        ì—­ì‚¬/ë¬¸í™”ìœ ì‚°         1.38              0            0.86   \n",
      "0   ì œì£¼ê´€ê´‘ì•ˆë‚´ì†Œ      ê´€ê´‘ì•ˆë‚´ì†Œ/ë§¤í‘œì†Œ         1.78              0            0.82   \n",
      "\n",
      "    final_score  \n",
      "75       0.2730  \n",
      "21       0.2681  \n",
      "36       0.2615  \n",
      "12       0.2585  \n",
      "0        0.2466  \n"
     ]
    }
   ],
   "source": [
    "# ê´€ê´‘ì§€ì—ì„œ ì¶”ì²œ ìƒìœ„ 5ê°œ ë½‘ê¸°\n",
    "recommended = score_places(\n",
    "    df=attractions,\n",
    "    user_lat=33.511111,\n",
    "    user_lng=126.492778,\n",
    "    user_category='',  # ì˜ˆ: ì‚¬ìš©ìê°€ 'ìì—°'ì„ ì„ í˜¸í•œë‹¤ê³  ì‘ë‹µ\n",
    "    max_distance_km=10,\n",
    "    w_content=0.7,\n",
    "    w_distance=0.3\n",
    ")\n",
    "\n",
    "print(recommended[['name', 'theme_category', 'distance_km', 'content_score', 'distance_score', 'final_score']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "6b42d954",
   "metadata": {},
   "outputs": [],
   "source": [
    "from geopy.distance import geodesic\n",
    "\n",
    "def score_based_recommendation(df, user_lat, user_lng, selected_category, max_distance_km=10,\n",
    "                                w_content=0.7, w_distance=0.3, top_n=5):\n",
    "    results = []\n",
    "\n",
    "    # 1. ê±°ë¦¬ ìµœëŒ€ê°’ ê³„ì‚° (ë¸Œë£¨íŠ¸í¬ìŠ¤ ì¤‘ ìµœì¥ê±°ë¦¬ ì°¾ê¸°ìš©)\n",
    "    max_possible_distance = 0\n",
    "    for _, row in df.iterrows():\n",
    "        if pd.isna(row['lat']) or pd.isna(row['lng']):\n",
    "            continue\n",
    "        try:\n",
    "            dist = geodesic((user_lat, user_lng), (row['lat'], row['lng'])).km\n",
    "            if dist > max_possible_distance:\n",
    "                max_possible_distance = dist\n",
    "        except:\n",
    "            continue\n",
    "\n",
    "    # 2. ì ìˆ˜ ê³„ì‚°\n",
    "    for _, row in df.iterrows():\n",
    "        if pd.isna(row['lat']) or pd.isna(row['lng']):\n",
    "            continue\n",
    "\n",
    "        try:\n",
    "            distance_km = geodesic((user_lat, user_lng), (row['lat'], row['lng'])).km\n",
    "        except:\n",
    "            continue\n",
    "\n",
    "        if distance_km > max_distance_km:\n",
    "            continue  # ë„ˆë¬´ ë©€ë©´ ì œì™¸\n",
    "\n",
    "        # ê±°ë¦¬ ì ìˆ˜\n",
    "        normalized_distance = distance_km / max_possible_distance if max_possible_distance else 1\n",
    "        distance_score = 1 - normalized_distance\n",
    "\n",
    "        # ì½˜í…ì¸  ì ìˆ˜: ì‚¬ìš©ìê°€ ì„ íƒí•œ ì¹´í…Œê³ ë¦¬ì™€ ì¼ì¹˜í•  ë•Œë§Œ ì ìˆ˜ ë¶€ì—¬\n",
    "        content_score = 1.0 if row.get('theme') == selected_category else 0.0\n",
    "\n",
    "        # ìµœì¢… ì ìˆ˜\n",
    "        total_score = w_content * content_score + w_distance * distance_score\n",
    "\n",
    "        result = row.to_dict()\n",
    "        result['distance_km'] = round(distance_km, 2)\n",
    "        result['score'] = round(total_score, 4)\n",
    "        results.append(result)\n",
    "\n",
    "    # 3. ìƒìœ„ Nê°œ ì •ë ¬ ë°˜í™˜\n",
    "    results = sorted(results, key=lambda x: x['score'], reverse=True)\n",
    "    return results[:top_n]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "ff4d86a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… ì´í˜¸í…Œìš°í•´ìˆ˜ìš•ì¥ | ê±°ë¦¬: 3.96km | ì ìˆ˜: 0.9778\n",
      "âœ… ì•Œì‘ì§€í•´ë³€ | ê±°ë¦¬: 5.23km | ì ìˆ˜: 0.9708\n",
      "âœ… ì‚¼ì–‘í•´ìˆ˜ìš•ì¥ | ê±°ë¦¬: 8.79km | ì ìˆ˜: 0.9508\n",
      "âœ… ì œì£¼ì¹´í˜ê±°ë¦¬ | ê±°ë¦¬: 0.9km | ì ìˆ˜: 0.295\n",
      "âœ… ìš©ë‘ì•”í•´ì•ˆë„ë¡œ | ê±°ë¦¬: 1.06km | ì ìˆ˜: 0.294\n"
     ]
    }
   ],
   "source": [
    "recommendations = score_based_recommendation(\n",
    "    df=attractions,\n",
    "    user_lat=33.511111,\n",
    "    user_lng=126.492778,\n",
    "    selected_category=\"í•´ìˆ˜ìš•ì¥\",  # ì‚¬ìš©ìê°€ ì„ íƒí•œ ì†Œì£¼ì œ\n",
    "    max_distance_km=10,     # 10km ì´ë‚´ë§Œ í•„í„°ë§\n",
    "    w_content=0.7,\n",
    "    w_distance=0.3,\n",
    "    top_n=5\n",
    ")\n",
    "\n",
    "for rec in recommendations:\n",
    "    print(f\"âœ… {rec['name']} | ê±°ë¦¬: {rec['distance_km']}km | ì ìˆ˜: {rec['score']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82dcb921",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# ê´€ê´‘ì§€ ë°ì´í„° ë¶ˆëŸ¬ì˜¤ê¸°\n",
    "\n",
    "df = pd.read_csv(\"data2.csv\",encoding='EUC-KR')\n",
    "# \"theme\" ì—´ì— ìˆëŠ” 'í­í¬' â†’ 'ê°•' ìœ¼ë¡œ í†µì¼\n",
    "df['theme'] = df['theme'].str.replace(\"í­í¬\", \"ê°•\", regex=False)\n",
    "# ë¶„ë¥˜ í•¨ìˆ˜ ì •ì˜\n",
    "def classify_theme_category(theme):\n",
    "    if pd.isna(theme):\n",
    "        return \"ê¸°íƒ€\"\n",
    "    if any(kw in theme for kw in [\"ì‚°\", \"ë°”ë‹¤\", \"ê³µì›\", \"ë“œë¼ì´ë¸Œ\", \"ë™êµ´\", \"ì‚°ì±…\", \"ê°•\"]):\n",
    "        return \"ìì—°/ê²½ì¹˜í˜•\"\n",
    "    elif any(kw in theme for kw in [\"ì‚¬ì°°\", \"ìœ ì ì§€\", \"ê³ íƒ\", \"ë¯¸ìˆ ê´€\", \"ì´¬ì˜ì§€\", \"ê¸°ë…ê´€\"]):\n",
    "        return \"ì—­ì‚¬/ë¬¸í™”í˜•\"\n",
    "    elif any(kw in theme for kw in [\"í…Œë§ˆíŒŒí¬\", \"ì²´í—˜ë§ˆì„\", \"ìŠ¤í¬ì¸ ì‹œì„¤\"]):\n",
    "        return \"ì•¡í‹°ë¹„í‹°í˜•\"\n",
    "    else:\n",
    "        return \"ê¸°íƒ€\"\n",
    "\n",
    "# ë¶„ë¥˜ ì ìš©\n",
    "df[\"theme_category\"] = df[\"theme\"].apply(classify_theme_category)\n",
    "\n",
    "# ê²°ê³¼ ì €ì¥ (ì„ íƒ)\n",
    "df.to_csv(\"ê´€ê´‘ì§€_ë¶„ë¥˜ì™„ë£Œ2.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e6877c8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# ë‘ ê°œì˜ CSV íŒŒì¼ ë¶ˆëŸ¬ì˜¤ê¸°\n",
    "df1 = pd.read_csv(\"final.csv\")\n",
    "df2 = pd.read_excel(\"ì„±ì‹œê²½ 211to422í•„í„°ë§.xlsx\")\n",
    "\n",
    "# ë‘ ë°ì´í„°ë¥¼ ì„¸ë¡œë¡œ ì´ì–´ë¶™ì´ê¸° (í–‰ ê¸°ì¤€ í•©ì¹˜ê¸°)\n",
    "merged_df = pd.concat([df1, df2], ignore_index=True)\n",
    "\n",
    "# ê²°ê³¼ ì €ì¥\n",
    "merged_df.to_csv(\"merged_result.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "0f9667a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ğŸ“¦ ê·¸ë£¹ 1:\n",
      " - ë™ì‚°ë¬¼ê°ê·¤ì²´í—˜ë†ì¥\n",
      " - ë´‰ë´‰ê°ê·¤ì²´í—˜ë†ì¥\n",
      " - ì œì£¼ì™•ê°ê·¤ì²´í—˜ë†ì¥\n",
      " - ê±¸ì„¸ì•…ê°ê·¤ì²´í—˜ë†ì¥\n",
      "\n",
      "ğŸ“¦ ê·¸ë£¹ 2:\n",
      " - ë„ê¹¨ë¹„ê³µì›\n",
      " - ë„ê¹¨ë¹„ë„ë¡œ\n",
      "\n",
      "ğŸ“¦ ê·¸ë£¹ 3:\n",
      " - ê°¯ê¹ì£¼ìƒì ˆë¦¬ëŒ€\n",
      " - ëŒ€í¬ì£¼ìƒì ˆë¦¬ëŒ€\n",
      "\n",
      "ğŸ“¦ ê·¸ë£¹ 4:\n",
      " - ê·€ë•í•´ì•ˆë„ë¡œ\n",
      " - í•¨ë•í•´ì•ˆë„ë¡œ\n",
      "\n",
      "ğŸ“¦ ê·¸ë£¹ 5:\n",
      " - ê¹€ë…•ë¯¸ë¡œê³µì›\n",
      " - ë…¹ì°¨ë¯¸ë¡œê³µì›\n",
      "\n",
      "ğŸ“¦ ê·¸ë£¹ 6:\n",
      " - ì‚°êµ¼ë¶€ë¦¬\n",
      " - êµ¼ë¶€ë¦¬\n",
      "\n",
      "ğŸ“¦ ê·¸ë£¹ 7:\n",
      " - ìˆ˜ì›”ë´‰\n",
      " - ìˆ˜ì›”ë´‰ì§€ì§ˆíŠ¸ë ˆì¼\n",
      "\n",
      "ğŸ“¦ ê·¸ë£¹ 8:\n",
      " - ì¢…ë‹¬ë¦¬í•´ì•ˆë„ë¡œ\n",
      " - ì¢…ë‹¬ë¦¬í•´ë³€\n",
      "\n",
      "ğŸ“¦ ê·¸ë£¹ 9:\n",
      " - ì œì£¼ë¯¼ì†ë§ˆì„\n",
      " - ì œì£¼ë¯¼ì†ì´Œ\n",
      "\n",
      "ğŸ“¦ ê·¸ë£¹ 10:\n",
      " - ë¹„ìë¦¼\n",
      " - ì œì£¼í‚¤ìœ„ë¹„ìë¦¼ë†ì›\n",
      "\n",
      "ğŸ“¦ ê·¸ë£¹ 11:\n",
      " - ì œì£¼ë™ë°±ë§ˆì„\n",
      " - ì œì£¼ë™ë°±ìˆ˜ëª©ì›\n",
      "\n",
      "ğŸ“¦ ê·¸ë£¹ 12:\n",
      " - ì§€ì§ˆíŠ¸ë ˆì¼\n",
      " - ìˆ˜ì›”ë´‰ì§€ì§ˆíŠ¸ë ˆì¼\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "# ê´€ê´‘ì§€ ë°ì´í„° ë¶ˆëŸ¬ì˜¤ê¸°\n",
    "df = pd.read_csv(\"merged_result.csv\")  # íŒŒì¼ëª…ì— ë§ê²Œ ìˆ˜ì •\n",
    "names = df['name'].fillna(\"\").astype(str)\n",
    "\n",
    "# TF-IDF ë²¡í„°í™” (ë¬¸ì ë‹¨ìœ„ n-gram ì‚¬ìš©í•˜ë©´ ë” ì˜ ì‘ë™)\n",
    "vectorizer = TfidfVectorizer(analyzer='char', ngram_range=(2, 3))\n",
    "tfidf_matrix = vectorizer.fit_transform(names)\n",
    "\n",
    "# Cosine similarity ê³„ì‚°\n",
    "cosine_sim = cosine_similarity(tfidf_matrix)\n",
    "\n",
    "# ìœ ì‚¬í•œ í•­ëª©ë¼ë¦¬ ê·¸ë£¹ìœ¼ë¡œ ë¬¶ê¸° (ì„ê³„ê°’ 0.6 ì´ìƒì´ë©´ ê°™ì€ ê·¸ë£¹ìœ¼ë¡œ íŒë‹¨)\n",
    "threshold = 0.4\n",
    "visited = set()\n",
    "groups = []\n",
    "\n",
    "for i in range(len(names)):\n",
    "    if i in visited:\n",
    "        continue\n",
    "    group = [names[i]]\n",
    "    visited.add(i)\n",
    "    for j in range(i + 1, len(names)):\n",
    "        if cosine_sim[i, j] >= threshold:\n",
    "            group.append(names[j])\n",
    "            visited.add(j)\n",
    "    if len(group) > 1:\n",
    "        groups.append(group)\n",
    "\n",
    "# ê²°ê³¼ ì¶œë ¥\n",
    "for idx, group in enumerate(groups, 1):\n",
    "    print(f\"\\nğŸ“¦ ê·¸ë£¹ {idx}:\")\n",
    "    for name in group:\n",
    "        print(\" -\", name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "343e92c8",
   "metadata": {
    "vscode": {
     "languageId": "ini"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# 1. ë¶„ë¥˜ëœ ê¸°ì¤€ ë°ì´í„° ë¡œë“œ\n",
    "classified_df = pd.read_excel(\"211to422.xlsx\")  # theme, theme_category í¬í•¨ëœ CSV\n",
    "# ì—´ ì´ë¦„: ['id', 'name', 'theme', 'theme_category']\n",
    "\n",
    "# 2. ì›ë³¸ ì „ì²´ ë°ì´í„° ë¡œë“œ (ì±„ì›Œì•¼ í•˜ëŠ” ëŒ€ìƒ)\n",
    "original_df = pd.read_csv(\"data_d.csv\")  # theme, theme_categoryê°€ ëˆ„ë½ë˜ì—ˆê±°ë‚˜ ë¹„ì–´ ìˆëŠ” ë°ì´í„°\n",
    "\n",
    "# 3. ID ê¸°ì¤€ ë³‘í•©í•˜ì—¬ theme, theme_category ì±„ìš°ê¸°\n",
    "merged_df = original_df.merge(classified_df[['id', 'theme', 'theme_category']], on='id', how='left', suffixes=('', '_filled'))\n",
    "\n",
    "# 4. ëˆ„ë½ëœ ê°’ì´ ìˆëŠ” ê²½ìš° ì±„ìš°ê¸°\n",
    "merged_df['theme'] = merged_df['theme'].combine_first(merged_df['theme_filled'])\n",
    "merged_df['theme_category'] = merged_df['theme_category'].combine_first(merged_df['theme_category_filled'])\n",
    "\n",
    "# 5. ë¶ˆí•„ìš”í•œ ë³´ì¡° ì—´ ì œê±°\n",
    "merged_df.drop(columns=['theme_filled', 'theme_category_filled'], inplace=True)\n",
    "\n",
    "# 6. ê²°ê³¼ ì €ì¥ (ì„ íƒì‚¬í•­)\n",
    "merged_df.to_csv(\"merged_data_with_theme.csv\", index=False)\n",
    "\n",
    "print(\"âœ… theme ë° theme_category ì—´ì´ ID ê¸°ì¤€ìœ¼ë¡œ ë³‘í•© ë° ì±„ì›Œì¡ŒìŠµë‹ˆë‹¤.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fc373cb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sl",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
